{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyannote\n",
    "\n",
    "# database related imports\n",
    "from pyannote.database import registry, FileFinder\n",
    "\n",
    "# training related imports\n",
    "from pyannote.audio import Pipeline, Model\n",
    "from pyannote.audio import pipelines\n",
    "from pyannote.audio.tasks import SpeakerDiarization\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "\n",
    "# metrics related imports\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "\n",
    "# other\n",
    "import os\n",
    "\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/database/registry.py:499: UserWarning: Replacing existing BP.SpeakerDiarization.VlaamseAudio protocol by the one defined in '/home/vicuser/bp-stemmen-onderscheiden/pyannote/database.yml'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "registry.load_database(\"database.yml\")\n",
    "\n",
    "protocol = registry.get_protocol(\"BP.SpeakerDiarization.VlaamseAudio\", {\"audio\":FileFinder()})\n",
    "\n",
    "for file in protocol.train():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeakerDiarization']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = registry.get_database(\"BP\")\n",
    "\n",
    "database.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyannote.database.custom.BP__SpeakerDiarization__VlaamseAudio"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocol.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained pyannote pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model from the pipeline\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=huggingface_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current error rate of the pipeline (possibly very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7f391de3a3e0>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7f391de3a260>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7f391de3a830>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7f3a2073b310>\n",
      "Diarization error rate is 0.0% for the pretrained model\n"
     ]
    }
   ],
   "source": [
    "metric = DiarizationErrorRate()\n",
    "\n",
    "for file in protocol.test():\n",
    "    print(file)\n",
    "    file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"])\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Timeline(uri=file20, segments=[])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"annotated\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/660b9e20307a2b0cdb400d0f80aadc04a701fc54/pytorch_model.bin`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -   6.33% of all chunks contain no speech at all.\n",
      "   -  82.41% contain 1 speaker or less\n",
      "   -  98.73% contain 2 speakers or less\n",
      "   - 100.00% contain 3 speakers or less\n",
      "Setting `max_speakers_per_chunk` to 2. You can override this value (or avoid this estimation step) by passing `max_speakers_per_chunk=2` to the task constructor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/audio/core/model.py:229: UserWarning: Model has been trained for a different task. For fine tuning or transfer learning, it is recommended to train task-dependent layers for a few epochs before training the whole model: ['activation', 'classifier'].\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_segm_model = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=huggingface_token)\n",
    "output_dir = \"./models\"\n",
    "\n",
    "task = SpeakerDiarization(\n",
    "    protocol=protocol,\n",
    "    batch_size=32,\n",
    "    vad_loss=\"bce\"\n",
    ")\n",
    "\n",
    "pretrained_segm_model.task = task\n",
    "pretrained_segm_model.prepare_data()\n",
    "pretrained_segm_model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.configure_optimizers = MethodType(configure_optimizers, pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/vicuser/bp-stemmen-onderscheiden/pyannote/DiarizationErrorRate exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                           Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ sincnet           │ SincNet          │ 42.6 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 32000] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                        [1, 60, 115] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ lstm              │ LSTM             │  1.4 M │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 115, 60] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [[1, 115, 256], [[8, 1, 128], [8, </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>│                   │                  │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                           1, 128]]] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ linear            │ ModuleList       │ 49.4 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ classifier        │ Linear           │    258 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 115, 128] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ activation        │ Sigmoid          │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 115, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ validation_metric │ MetricCollection │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m                          Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ sincnet           │ SincNet          │ 42.6 K │ train │\u001b[37m \u001b[0m\u001b[37m[1, 1, 32000]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                       [1, 60, 115]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ lstm              │ LSTM             │  1.4 M │ train │\u001b[37m \u001b[0m\u001b[37m [1, 115, 60]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [[1, 115, 256], [[8, 1, 128], [8,\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m   \u001b[0m│                   │                  │        │       │\u001b[37m               \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                          1, 128]]]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ linear            │ ModuleList       │ 49.4 K │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ classifier        │ Linear           │    258 │ train │\u001b[37m \u001b[0m\u001b[37m[1, 115, 128]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ activation        │ Sigmoid          │      0 │ train │\u001b[37m \u001b[0m\u001b[37m  [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ validation_metric │ MetricCollection │      0 │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 27                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 27                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` \n",
       "has `__len__` defined. In combination with multi-process data loading (when num_workers &gt; 1), `__len__` could be \n",
       "inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` \n",
       "has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be \n",
       "inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training \n",
       "batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training \n",
       "batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vicuser/bp-stemmen-onderscheiden/pyannote/DiarizationErrorRate/epoch=9-v2.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getrainde model terug in aan de pipeline toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import pipelines\n",
    "finetuned_pipeline = pipelines.SpeakerDiarization(\n",
    "    segmentation=trained_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: instantiate after finetuning [github notebook](https://github.com/pyannote/pyannote-audio/blob/main/tutorials/adapting_pretrained_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f38e18572b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pipeline.instantiate(\n",
    "    pretrained_pipeline.parameters(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test result of trained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiarizationErrorRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:304\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:189\u001b[0m, in \u001b[0;36mSpeakerDiarization.default_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mtest():\n\u001b[0;32m----> 2\u001b[0m     file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinetuned_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     metric(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotation\u001b[39m\u001b[38;5;124m\"\u001b[39m], file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m], uem\u001b[38;5;241m=\u001b[39mfile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotated\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiarization error rate is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mabs\u001b[39m(metric)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% for the pretrained model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:306\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parameters()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate(default_parameters)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied."
     ]
    }
   ],
   "source": [
    "for file in protocol.test():\n",
    "    file[\"finetuned pipeline\"] = finetuned_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"finetuned pipeline\"], uem=file[\"annotated\"])\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")\n",
    "\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
