{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyannote\n",
    "\n",
    "# database related imports\n",
    "from pyannote.database import registry, FileFinder\n",
    "\n",
    "# training related imports\n",
    "from pyannote.audio import Pipeline, Model\n",
    "from pyannote.audio import pipelines\n",
    "from pyannote.audio.tasks import SpeakerDiarization\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "\n",
    "# metrics related imports\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "\n",
    "# other\n",
    "import os\n",
    "\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/database/registry.py:499: UserWarning: Replacing existing BP.SpeakerDiarization.VlaamseAudio protocol by the one defined in '/home/vicuser/bp-stemmen-onderscheiden/pyannote/database.yml'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "registry.load_database(\"database.yml\")\n",
    "\n",
    "protocol = registry.get_protocol(\"BP.SpeakerDiarization.VlaamseAudio\", {\"audio\":FileFinder()})\n",
    "\n",
    "for file in protocol.train():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n",
    "\n",
    "for file in protocol.test():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n",
    "\n",
    "for file in protocol.development():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeakerDiarization']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = registry.get_database(\"BP\")\n",
    "\n",
    "database.get_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained pyannote pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model from the pipeline\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=huggingface_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current error rate of the pipeline (possibly very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7f6e16be2a10>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mtest():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m----> 5\u001b[0m     file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpretrained_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     metric(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotation\u001b[39m\u001b[38;5;124m\"\u001b[39m], file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m], uem\u001b[38;5;241m=\u001b[39mfile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotated\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiarization error rate is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mabs\u001b[39m(metric)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% for the pretrained model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:327\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessors\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    325\u001b[0m     file \u001b[38;5;241m=\u001b[39m ProtocolFile(file, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessors)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:478\u001b[0m, in \u001b[0;36mSpeakerDiarization.apply\u001b[0;34m(self, file, num_speakers, min_speakers, max_speakers, return_embeddings, hook)\u001b[0m\n\u001b[1;32m    470\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_hook(file, hook\u001b[38;5;241m=\u001b[39mhook)\n\u001b[1;32m    472\u001b[0m num_speakers, min_speakers, max_speakers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_num_speakers(\n\u001b[1;32m    473\u001b[0m     num_speakers\u001b[38;5;241m=\u001b[39mnum_speakers,\n\u001b[1;32m    474\u001b[0m     min_speakers\u001b[38;5;241m=\u001b[39mmin_speakers,\n\u001b[1;32m    475\u001b[0m     max_speakers\u001b[38;5;241m=\u001b[39mmax_speakers,\n\u001b[1;32m    476\u001b[0m )\n\u001b[0;32m--> 478\u001b[0m segmentations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_segmentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m, segmentations)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m#   shape: (num_chunks, num_frames, local_num_speakers)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:224\u001b[0m, in \u001b[0;36mSpeakerDiarization.get_segmentations\u001b[0;34m(self, file, hook)\u001b[0m\n\u001b[1;32m    222\u001b[0m         file[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCACHED_SEGMENTATION] \u001b[38;5;241m=\u001b[39m segmentations\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     segmentations: SlidingWindowFeature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m segmentations\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/inference.py:421\u001b[0m, in \u001b[0;36mInference.__call__\u001b[0;34m(self, file, hook)\u001b[0m\n\u001b[1;32m    418\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39maudio(file)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msliding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m outputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, Tuple[np\u001b[38;5;241m.\u001b[39mndarray]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(waveform[\u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__first_sample\u001b[39m(outputs: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/inference.py:313\u001b[0m, in \u001b[0;36mInference.slide\u001b[0;34m(self, waveform, sample_rate, hook)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, num_chunks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m    311\u001b[0m     batch: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m chunks[c : c \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 313\u001b[0m     batch_outputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, Tuple[np\u001b[38;5;241m.\u001b[39mndarray]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     _ \u001b[38;5;241m=\u001b[39m map_with_specifications(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mspecifications, __append_batch, outputs, batch_outputs\n\u001b[1;32m    317\u001b[0m     )\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/inference.py:215\u001b[0m, in \u001b[0;36mInference.infer\u001b[0;34m(self, chunks)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_oom_error(exception):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/models/segmentation/PyanNet.py:226\u001b[0m, in \u001b[0;36mPyanNet.forward\u001b[0;34m(self, waveforms)\u001b[0m\n\u001b[1;32m    223\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msincnet(waveforms)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mlstm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonolithic\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 226\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch feature frame -> batch frame feature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m rearrange(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch feature frame -> batch frame feature\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric = DiarizationErrorRate()\n",
    "\n",
    "for file in protocol.test():\n",
    "    print(file)\n",
    "    file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"])\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7f6e16bfc370>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"pretrained pipeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiIAAADZCAYAAACtpyhbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAE9BJREFUeJzt3X+M13UdwPHX9wRO7O4LHD/uRwcEojATiLSxq1UmhJBjmq7MGEMqWogsXFmjJeQ/KrS12Wq61Qr+CCsrajnJWCKuJFIaAdJIbjUsOFgw4IBQ5N794fjmV/lx2r3ve3c8Htttd9/P576+P3+8fH/Z877fTyGllAIAAAAAACCDqkovAAAAAAAA6LuECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACy6deZkzo6OmLv3r1RW1sbhUIh95oAAAAAAIAeLKUU7e3t0dTUFFVV53/PQ6dCxN69e2PkyJFdsjgAAAAAAKBveOmll6K5ufm853QqRNTW1paesFgs/v8rAwAAAAAAeq2jR4/GyJEjS/3gfDoVIs58HFOxWBQiAAAAAACAiIhO3c7BzaoBAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIJt+nTkppRQREUePHs26GAAAAAAAoOc70wvO9IPz6VSIaG9vj4iIkSNH/h/LAgAAAAAA+pL29vYYNGjQec8ppE7kio6Ojti7d2/U1tZGoVDosgVCdzp69GiMHDkyXnrppSgWi5VeDvR6Zgq6lpmCrmWmoOuZK+haZgq6lpnqfimlaG9vj6ampqiqOv9dIDr1joiqqqpobm7uksVBpRWLRf8zgi5kpqBrmSnoWmYKup65gq5lpqBrmanudaF3QpzhZtUAAAAAAEA2QgQAAAAAAJCNEMFFo7q6OpYvXx7V1dWVXgr0CWYKupaZgq5lpqDrmSvoWmYKupaZ6tk6dbNqAAAAAACAt8M7IgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEi6FO+8Y1vRKFQKPuaMGFC6fjJkydj0aJFMXTo0KipqYlbb7019u/fX8EVQ8/zzDPPxOzZs6OpqSkKhUL88pe/LDueUoply5ZFY2NjDBw4MKZPnx4vvvhi2TmHDh2KOXPmRLFYjMGDB8dnP/vZOHbsWDdeBfQcF5qpO+64401718yZM8vOMVPwmgceeCDe9773RW1tbYwYMSJuvvnm2LVrV9k5nXm9t2fPnrjxxhvjsssuixEjRsQ999wTr776andeCvQInZmp66677k371Be+8IWyc8wU/M/DDz8ckyZNimKxGMViMVpaWmLdunWl4/YpeGsuNFP2qd5DiKDPefe73x379u0rff3+978vHbv77rvj17/+dTz22GOxcePG2Lt3b9xyyy0VXC30PMePH4/JkyfHd7/73bMeX7lyZXz729+ORx55JDZv3hzveMc74oYbboiTJ0+WzpkzZ0688MILsX79+nj88cfjmWeeic9//vPddQnQo1xopiIiZs6cWbZ3Pfroo2XHzRS8ZuPGjbFo0aL44x//GOvXr49Tp07FjBkz4vjx46VzLvR67/Tp03HjjTfGK6+8Es8++2ysXr06Vq1aFcuWLavEJUFFdWamIiIWLFhQtk+tXLmydMxMQbnm5uZ48MEHY8uWLfH888/H9ddfHzfddFO88MILEWGfgrfqQjMVYZ/qNRL0IcuXL0+TJ08+67HDhw+n/v37p8cee6z02F//+tcUEWnTpk3dtELoXSIirV27tvRzR0dHamhoSN/85jdLjx0+fDhVV1enRx99NKWU0s6dO1NEpOeee650zrp161KhUEj/+te/um3t0BO9caZSSmnevHnppptuOufvmCk4twMHDqSISBs3bkwpde713hNPPJGqqqpSW1tb6ZyHH344FYvF9PLLL3fvBUAP88aZSimlD3/4w+mLX/ziOX/HTMGFDRkyJH3/+9+3T0EXOTNTKdmnehPviKDPefHFF6OpqSnGjh0bc+bMiT179kRExJYtW+LUqVMxffr00rkTJkyIUaNGxaZNmyq1XOhV/v73v0dbW1vZHA0aNCimTp1amqNNmzbF4MGD49prry2dM3369KiqqorNmzd3+5qhN3j66adjxIgRMX78+Fi4cGEcPHiwdMxMwbkdOXIkIiLq6uoionOv9zZt2hQTJ06M+vr60jk33HBDHD16tOwv6+Bi9MaZOuNHP/pRDBs2LK6++upYunRpnDhxonTMTMG5nT59On784x/H8ePHo6WlxT4F/6c3ztQZ9qneoV+lFwBdaerUqbFq1aoYP3587Nu3L+6777744Ac/GDt27Ii2trYYMGBADB48uOx36uvro62trTILhl7mzKy8fgM/8/OZY21tbTFixIiy4/369Yu6ujqzBmcxc+bMuOWWW2LMmDHR2toaX/va12LWrFmxadOmuOSSS8wUnENHR0csWbIkPvCBD8TVV18dEdGp13ttbW1n3cfOHIOL1dlmKiLi05/+dIwePTqamppi27Zt8dWvfjV27doVv/jFLyLCTMHZbN++PVpaWuLkyZNRU1MTa9eujauuuiq2bt1qn4K34VwzFWGf6k2ECPqUWbNmlb6fNGlSTJ06NUaPHh0//elPY+DAgRVcGQCc3ac+9anS9xMnToxJkybF5ZdfHk8//XRMmzatgiuDnm3RokWxY8eOsvuBAW/fuWbq9fckmjhxYjQ2Nsa0adOitbU1Lr/88u5eJvQK48ePj61bt8aRI0fiZz/7WcybNy82btxY6WVBr3WumbrqqqvsU72Ij2aiTxs8eHBceeWVsXv37mhoaIhXXnklDh8+XHbO/v37o6GhoTILhF7mzKzs37+/7PHXz1FDQ0McOHCg7Pirr74ahw4dMmvQCWPHjo1hw4bF7t27I8JMwdncdddd8fjjj8eGDRuiubm59HhnXu81NDScdR87cwwuRueaqbOZOnVqRETZPmWmoNyAAQNi3Lhxcc0118QDDzwQkydPjoceesg+BW/TuWbqbOxTPZcQQZ927NixaG1tjcbGxrjmmmuif//+8bvf/a50fNeuXbFnz56yz5UDzm3MmDHR0NBQNkdHjx6NzZs3l+aopaUlDh8+HFu2bCmd89RTT0VHR0fpBQFwbv/85z/j4MGD0djYGBFmCl4vpRR33XVXrF27Np566qkYM2ZM2fHOvN5raWmJ7du3lwW+9evXR7FYLL3FHy4WF5qps9m6dWtERNk+Zabg/Do6OuLll1+2T0EXOTNTZ2Of6rkKKaVU6UVAV/nyl78cs2fPjtGjR8fevXtj+fLlsXXr1ti5c2cMHz48Fi5cGE888USsWrUqisViLF68OCIinn322QqvHHqOY8eOlf5yYMqUKfGtb30rPvKRj0RdXV2MGjUqVqxYEQ8++GCsXr06xowZE/fee29s27Ytdu7cGZdeemlEvPYxafv3749HHnkkTp06FfPnz49rr7021qxZU8lLg4o430zV1dXFfffdF7feems0NDREa2trfOUrX4n29vbYvn17VFdXR4SZgjPuvPPOWLNmTfzqV7+K8ePHlx4fNGhQ6WM4L/R67/Tp0/Ge97wnmpqaYuXKldHW1hZz586Nz33uc3H//fd3/0VBBV1oplpbW2PNmjXxsY99LIYOHRrbtm2Lu+++O5qbm0sfM2OmoNzSpUtj1qxZMWrUqGhvb481a9bEihUr4sknn4yPfvSj9il4i843U2PHjrVP9SYJ+pDbbrstNTY2pgEDBqR3vvOd6bbbbku7d+8uHf/Pf/6T7rzzzjRkyJB02WWXpY9//ONp3759FVwx9DwbNmxIEfGmr3nz5qWUUuro6Ej33ntvqq+vT9XV1WnatGlp165dZc9x8ODBdPvtt6eamppULBbT/PnzU3t7ewWuBirvfDN14sSJNGPGjDR8+PDUv3//NHr06LRgwYLU1tZW9hxmCl5ztlmKiPTDH/6wdE5nXu/94x//SLNmzUoDBw5Mw4YNS1/60pfSqVOnuvlqoPIuNFN79uxJH/rQh1JdXV2qrq5O48aNS/fcc086cuRI2fOYKfifz3zmM2n06NFpwIABafjw4WnatGnpt7/9bem4fQremvPNlH2qd/GOCAAAAAAAIBv3iAAAAAAAALIRIgAAAAAAgGyECAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAoc8cdd8TNN99c6WUAAAB9RL9KLwAAAOg+hULhvMeXL18eDz30UKSUumlFAABAXydEAADARWTfvn2l73/yk5/EsmXLYteuXaXHampqoqamphJLAwAA+igfzQQAABeRhoaG0tegQYOiUCiUPVZTU/Omj2a67rrrYvHixbFkyZIYMmRI1NfXx/e+9704fvx4zJ8/P2pra2PcuHGxbt26sv/Wjh07YtasWVFTUxP19fUxd+7c+Pe//93NVwwAAFSaEAEAAFzQ6tWrY9iwYfGnP/0pFi9eHAsXLoxPfOIT8f73vz/+/Oc/x4wZM2Lu3Llx4sSJiIg4fPhwXH/99TFlypR4/vnn4ze/+U3s378/PvnJT1b4SgAAgO4mRAAAABc0efLk+PrXvx5XXHFFLF26NC699NIYNmxYLFiwIK644opYtmxZHDx4MLZt2xYREd/5zndiypQpcf/998eECRNiypQp8YMf/CA2bNgQf/vb3yp8NQAAQHdyjwgAAOCCJk2aVPr+kksuiaFDh8bEiRNLj9XX10dExIEDByIi4i9/+Uts2LDhrPebaG1tjSuvvDLzigEAgJ5CiAAAAC6of//+ZT8XCoWyxwqFQkREdHR0RETEsWPHYvbs2bFixYo3PVdjY2PGlQIAAD2NEAEAAHS59773vfHzn/883vWud0W/fv7ZAQAAFzP3iAAAALrcokWL4tChQ3H77bfHc889F62trfHkk0/G/Pnz4/Tp05VeHgAA0I2ECAAAoMs1NTXFH/7whzh9+nTMmDEjJk6cGEuWLInBgwdHVZV/hgAAwMWkkFJKlV4EAAAAAADQN/lTJAAAAAAAIBshAgAAAAAAyEaIAAAAAAAAshEiAAAAAACAbIQIAAAAAAAgGyECAAAAAADIRogAAAAAAACyESIAAAAAAIBshAgAAAAAACAbIQIAAAAAAMhGiAAAAAAAALIRIgAAAAAAgGz+C67C+JCEKbD0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7f6e1d6d0460>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"annotation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/660b9e20307a2b0cdb400d0f80aadc04a701fc54/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization at 0x7f6e1f332a70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyannote.audio\n",
    "import pyannote.audio.tasks\n",
    "\n",
    "\n",
    "pretrained_segm_model = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=huggingface_token)\n",
    "output_dir = \"./models\"\n",
    "\n",
    "task = pyannote.audio.tasks.Segmentation(\n",
    "    protocol,\n",
    "    batch_size=32,\n",
    "    vad_loss=\"bce\"\n",
    ")\n",
    "\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -   6.33% of all chunks contain no speech at all.\n",
      "   -  82.41% contain 1 speaker or less\n",
      "   -  98.73% contain 2 speakers or less\n",
      "   - 100.00% contain 3 speakers or less\n",
      "Setting `max_speakers_per_chunk` to 2. You can override this value (or avoid this estimation step) by passing `max_speakers_per_chunk=2` to the task constructor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/audio/core/model.py:229: UserWarning: Model has been trained for a different task. For fine tuning or transfer learning, it is recommended to train task-dependent layers for a few epochs before training the whole model: ['activation', 'classifier'].\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_segm_model.task = task\n",
    "# pretrained_segm_model.task.prepare_data()\n",
    "pretrained_segm_model.prepare_data()\n",
    "pretrained_segm_model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.configure_optimizers = MethodType(configure_optimizers, pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                           Out sizes </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> sincnet            SincNet           42.6 K  train <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 32000] </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                        [1, 60, 115] </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> lstm               LSTM               1.4 M  train <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 115, 60] </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [[1, 115, 256], [[8, 1, 128], [8, </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">               </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                           1, 128]]] </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> linear             ModuleList        49.4 K  train <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> classifier         Linear               258  train <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 115, 128] </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span> activation         Sigmoid                0  train <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 115, 2] </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span> validation_metric  MetricCollection       0  train <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m                          Out sizes\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m sincnet            SincNet           42.6 K  train \u001b[37m \u001b[0m\u001b[37m[1, 1, 32000]\u001b[0m\u001b[37m \u001b[0m\u001b[37m \u001b[0m\u001b[37m                       [1, 60, 115]\u001b[0m\u001b[37m \u001b[0m\n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m lstm               LSTM               1.4 M  train \u001b[37m \u001b[0m\u001b[37m [1, 115, 60]\u001b[0m\u001b[37m \u001b[0m\u001b[37m \u001b[0m\u001b[37m  [[1, 115, 256], [[8, 1, 128], [8,\u001b[0m\u001b[37m \u001b[0m\n",
       "\u001b[2m   \u001b[0m                                                    \u001b[37m               \u001b[0m\u001b[37m \u001b[0m\u001b[37m                          1, 128]]]\u001b[0m\u001b[37m \u001b[0m\n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m linear             ModuleList        49.4 K  train \u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m\n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m classifier         Linear               258  train \u001b[37m \u001b[0m\u001b[37m[1, 115, 128]\u001b[0m\u001b[37m \u001b[0m\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m\n",
       "\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m activation         Sigmoid                0  train \u001b[37m \u001b[0m\u001b[37m  [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m\n",
       "\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m validation_metric  MetricCollection       0  train \u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 27                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 27                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "An invalid dataloader was returned from `PyanNet.val_dataloader()`. Found None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:386\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# A prefix in the message to disambiguate between the train- and (optional) val dataloader that .fit() accepts\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_segm_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1054\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1054\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1083\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1083\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:120\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;129m@_no_grad_context\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[_OUT_DICT]:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:189\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dl \u001b[38;5;129;01min\u001b[39;00m combined_loader\u001b[38;5;241m.\u001b[39mflattened:\n\u001b[0;32m--> 189\u001b[0m     \u001b[43m_check_dataloader_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     dl \u001b[38;5;241m=\u001b[39m _process_dataloader(trainer, trainer_fn, stage, dl)\n\u001b[1;32m    191\u001b[0m     dataloaders\u001b[38;5;241m.\u001b[39mappend(dl)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:402\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_overridden(source\u001b[38;5;241m.\u001b[39mname, source\u001b[38;5;241m.\u001b[39minstance):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn invalid dataloader was passed to `Trainer.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_fn\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdataloaders=...)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataloader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Either pass the dataloader to the `.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_fn\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()` method OR implement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(self):` in your LightningModule/LightningDataModule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m     )\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn invalid dataloader was returned from `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(source\u001b[38;5;241m.\u001b[39minstance)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataloader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: An invalid dataloader was returned from `PyanNet.val_dataloader()`. Found None."
     ]
    }
   ],
   "source": [
    "trainer.fit(pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vicuser/bp-stemmen-onderscheiden/pyannote/DiarizationErrorRate/epoch=9-v2.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getrainde model terug in aan de pipeline toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import pipelines\n",
    "finetuned_pipeline = pipelines.SpeakerDiarization(\n",
    "    segmentation=trained_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: instantiate after finetuning [github notebook](https://github.com/pyannote/pyannote-audio/blob/main/tutorials/adapting_pretrained_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f38e18572b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pipeline.instantiate(\n",
    "    pretrained_pipeline.parameters(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test result of trained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiarizationErrorRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:304\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:189\u001b[0m, in \u001b[0;36mSpeakerDiarization.default_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mtest():\n\u001b[0;32m----> 2\u001b[0m     file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinetuned_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     metric(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotation\u001b[39m\u001b[38;5;124m\"\u001b[39m], file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m], uem\u001b[38;5;241m=\u001b[39mfile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotated\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiarization error rate is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mabs\u001b[39m(metric)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% for the pretrained model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:306\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parameters()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate(default_parameters)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied."
     ]
    }
   ],
   "source": [
    "for file in protocol.test():\n",
    "    file[\"finetuned pipeline\"] = finetuned_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"finetuned pipeline\"], uem=file[\"annotated\"])\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")\n",
    "\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
