{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyannote\n",
    "\n",
    "# database related imports\n",
    "from pyannote.database import registry, FileFinder\n",
    "\n",
    "# training related imports\n",
    "from pyannote.audio import Pipeline, Model\n",
    "from pyannote.audio import Inference\n",
    "from pyannote.audio.tasks import SpeakerDiarization\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "\n",
    "# metrics related imports\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "\n",
    "# other\n",
    "import os\n",
    "\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyannote\\database\\registry.py:499: UserWarning: Replacing existing BP.SpeakerDiarization.VlaamseAudio protocol by the one defined in 'C:\\Users\\verho\\Documents\\School\\2024-2025\\Bacherlorproef\\bp-stemmen-onderscheiden\\pyannote\\database.yml'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "registry.load_database(\"database.yml\")\n",
    "\n",
    "protocol = registry.get_protocol(\"BP.SpeakerDiarization.VlaamseAudio\", {\"audio\":FileFinder()})\n",
    "\n",
    "for file in protocol.train():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeakerDiarization']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = registry.get_database(\"BP\")\n",
    "\n",
    "database.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyannote.database.custom.BP__SpeakerDiarization__VlaamseAudio"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocol.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained pyannote pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "# get the model from the pipeline\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=huggingface_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current error rate of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x00000225E90AE9C0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x00000225EA329250>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x00000225E996E180>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x00000225E9E1FC20>\n",
      "Diarization error rate is 25.0% for the pretrained model\n"
     ]
    }
   ],
   "source": [
    "metric = DiarizationErrorRate()\n",
    "\n",
    "for file in protocol.test():\n",
    "    print(file)\n",
    "    file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"])\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x225ea80d580>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"annotation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\verho\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\660b9e20307a2b0cdb400d0f80aadc04a701fc54\\pytorch_model.bin`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\\n",
       "Python312\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\\n",
       "Python312\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cpu. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -   6.33% of all chunks contain no speech at all.\n",
      "   -  82.41% contain 1 speaker or less\n",
      "   -  98.73% contain 2 speakers or less\n",
      "   - 100.00% contain 3 speakers or less\n",
      "Setting `max_speakers_per_chunk` to 2. You can override this value (or avoid this estimation step) by passing `max_speakers_per_chunk=2` to the task constructor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyannote\\audio\\core\\model.py:229: UserWarning: Model has been trained for a different task. For fine tuning or transfer learning, it is recommended to train task-dependent layers for a few epochs before training the whole model: ['activation', 'classifier'].\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_segm_model = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=huggingface_token)\n",
    "output_dir = \"./models\"\n",
    "\n",
    "task = SpeakerDiarization(\n",
    "    protocol=protocol,\n",
    "    batch_size=32,\n",
    "    vad_loss=\"bce\"\n",
    ")\n",
    "\n",
    "pretrained_segm_model.task = task\n",
    "pretrained_segm_model.prepare_data()\n",
    "pretrained_segm_model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.configure_optimizers = MethodType(configure_optimizers, pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                           Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ sincnet           │ SincNet          │ 42.6 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 32000] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                        [1, 60, 115] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ lstm              │ LSTM             │  1.4 M │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 115, 60] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [[1, 115, 256], [[8, 1, 128], [8, </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>│                   │                  │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                           1, 128]]] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ linear            │ ModuleList       │ 49.4 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ classifier        │ Linear           │    258 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 115, 128] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ activation        │ Sigmoid          │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 115, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ validation_metric │ MetricCollection │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m                          Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ sincnet           │ SincNet          │ 42.6 K │ train │\u001b[37m \u001b[0m\u001b[37m[1, 1, 32000]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                       [1, 60, 115]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ lstm              │ LSTM             │  1.4 M │ train │\u001b[37m \u001b[0m\u001b[37m [1, 115, 60]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [[1, 115, 256], [[8, 1, 128], [8,\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m   \u001b[0m│                   │                  │        │       │\u001b[37m               \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                          1, 128]]]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ linear            │ ModuleList       │ 49.4 K │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ classifier        │ Linear           │    258 │ train │\u001b[37m \u001b[0m\u001b[37m[1, 115, 128]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ activation        │ Sigmoid          │      0 │ train │\u001b[37m \u001b[0m\u001b[37m  [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ validation_metric │ MetricCollection │      0 │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 27                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 27                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\\n",
       "Python312\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\\n",
       "Python312\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\\n",
       "Python312\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting \n",
       "`persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\\n",
       "Python312\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting \n",
       "`persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'pyannote.database.registry.BP'>: attribute lookup BP on pyannote.database.registry failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_segm_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\trainer\\trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\trainer\\trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    571\u001b[0m     ckpt_path,\n\u001b[0;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\trainer\\trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1024\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1050\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\loops\\utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:122\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_start()\n\u001b[0;32m    124\u001b[0m data_fetcher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:258\u001b[0m, in \u001b[0;36m_EvaluationLoop.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m combined_loader\u001b[38;5;241m.\u001b[39mlimits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batches\n\u001b[0;32m    257\u001b[0m data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# add the previous `fetched` value to properly track `is_last_batch` with no prefetching\u001b[39;00m\n\u001b[0;32m    261\u001b[0m data_fetcher\u001b[38;5;241m.\u001b[39mfetched \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mready\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\loops\\fetchers.py:105\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_PrefetchDataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;66;03m# ignore pre-fetching, it's not necessary\u001b[39;00m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\loops\\fetchers.py:52\u001b[0m, in \u001b[0;36m_DataFetcher.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_DataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:351\u001b[0m, in \u001b[0;36mCombinedLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m _SUPPORTED_MODES[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterator\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    350\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflattened, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits)\n\u001b[1;32m--> 351\u001b[0m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m iterator\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:155\u001b[0m, in \u001b[0;36m_Sequential.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_current_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:173\u001b[0m, in \u001b[0;36m_Sequential._load_current_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_current_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# Load a single DataLoader, prevents multiple sets of workers from starting unnecessarily\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterables):\n\u001b[1;32m--> 173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m# No more iterables to step through, return an empty list\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:422\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1139\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class 'pyannote.database.registry.BP'>: attribute lookup BP on pyannote.database.registry failed"
     ]
    }
   ],
   "source": [
    "trainer.fit(pretrained_segm_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
