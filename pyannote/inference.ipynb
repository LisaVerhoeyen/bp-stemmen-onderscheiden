{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyannote\n",
    "\n",
    "# database related imports\n",
    "from pyannote.database import registry, FileFinder\n",
    "\n",
    "# training related imports\n",
    "from pyannote.audio import Pipeline, Model\n",
    "from pyannote.audio import pipelines\n",
    "from pyannote.audio.tasks import SpeakerDiarization\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "\n",
    "# metrics related imports\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "\n",
    "# other\n",
    "import os\n",
    "\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/database/registry.py:499: UserWarning: Replacing existing BP.SpeakerDiarization.VlaamseAudio protocol by the one defined in '/home/vicuser/bp-stemmen-onderscheiden/pyannote/database.yml'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "registry.load_database(\"database.yml\")\n",
    "\n",
    "protocol = registry.get_protocol(\"BP.SpeakerDiarization.VlaamseAudio\", {\"audio\":FileFinder()})\n",
    "\n",
    "for file in protocol.train():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeakerDiarization']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = registry.get_database(\"BP\")\n",
    "\n",
    "database.get_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained pyannote pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model from the pipeline\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=huggingface_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current error rate of the pipeline (possibly very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7fec4037afb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7fec41c8b190>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7fec40548040>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x7fed4420ac50>\n",
      "Diarization error rate is 0.0% for the pretrained model\n"
     ]
    }
   ],
   "source": [
    "metric = DiarizationErrorRate()\n",
    "\n",
    "for file in protocol.test():\n",
    "    print(file)\n",
    "    file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"])\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7fec403bd9f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"pretrained pipeline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/660b9e20307a2b0cdb400d0f80aadc04a701fc54/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyanNet(\n",
       "  (sincnet): SincNet(\n",
       "    (wav_norm1d): InstanceNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv1d): ModuleList(\n",
       "      (0): Encoder(\n",
       "        (filterbank): ParamSincFB()\n",
       "      )\n",
       "      (1): Conv1d(80, 60, kernel_size=(5,), stride=(1,))\n",
       "      (2): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "    (pool1d): ModuleList(\n",
       "      (0-2): 3 x MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (norm1d): ModuleList(\n",
       "      (0): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (1-2): 2 x InstanceNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(60, 128, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (linear): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_segm_model = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=huggingface_token)\n",
    "pretrained_segm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/660b9e20307a2b0cdb400d0f80aadc04a701fc54/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m task \u001b[38;5;241m=\u001b[39m pyannote\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mSegmentation(\n\u001b[1;32m      9\u001b[0m     protocol\u001b[38;5;241m=\u001b[39mprotocol,\n\u001b[1;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     11\u001b[0m     vad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbce\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m pretrained_segm_model\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m---> 15\u001b[0m \u001b[43mpretrained_segm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m pretrained_segm_model\u001b[38;5;241m.\u001b[39msetup()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/model.py:195\u001b[0m, in \u001b[0;36mModel.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprepare_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/task.py:599\u001b[0m, in \u001b[0;36mTask.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m unique_labels\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_validation:\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_prepare_data(prepared_data)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# save prepared data on the disk\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/tasks/segmentation/mixins.py:293\u001b[0m, in \u001b[0;36mSegmentationTask.prepare_validation\u001b[0;34m(self, prepared_data)\u001b[0m\n\u001b[1;32m    287\u001b[0m             start_time \u001b[38;5;241m=\u001b[39m annotated_region[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration\n\u001b[1;32m    288\u001b[0m             validation_chunks\u001b[38;5;241m.\u001b[39mappend((file_id, start_time, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration))\n\u001b[1;32m    290\u001b[0m dtype \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    291\u001b[0m     (\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 293\u001b[0m         get_dtype(\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalidation_chunks\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    294\u001b[0m     ),\n\u001b[1;32m    295\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    296\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    297\u001b[0m ]\n\u001b[1;32m    299\u001b[0m prepared_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(validation_chunks, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    300\u001b[0m validation_chunks\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pyannote.audio\n",
    "import pyannote.audio.tasks\n",
    "\n",
    "\n",
    "pretrained_segm_model = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=huggingface_token)\n",
    "output_dir = \"./models\"\n",
    "\n",
    "task = pyannote.audio.tasks.Segmentation(\n",
    "    protocol=protocol,\n",
    "    batch_size=32,\n",
    "    vad_loss=\"bce\"\n",
    ")\n",
    "\n",
    "pretrained_segm_model.task = task\n",
    "pretrained_segm_model.prepare_data()\n",
    "pretrained_segm_model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.configure_optimizers = MethodType(configure_optimizers, pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/vicuser/bp-stemmen-onderscheiden/pyannote/DiarizationErrorRate exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                           Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ sincnet           │ SincNet          │ 42.6 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 32000] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                        [1, 60, 115] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ lstm              │ LSTM             │  1.4 M │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 115, 60] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [[1, 115, 256], [[8, 1, 128], [8, </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>│                   │                  │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                           1, 128]]] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ linear            │ ModuleList       │ 49.4 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ classifier        │ Linear           │    258 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 115, 128] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ activation        │ Sigmoid          │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 115, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ validation_metric │ MetricCollection │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m                          Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ sincnet           │ SincNet          │ 42.6 K │ train │\u001b[37m \u001b[0m\u001b[37m[1, 1, 32000]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                       [1, 60, 115]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ lstm              │ LSTM             │  1.4 M │ train │\u001b[37m \u001b[0m\u001b[37m [1, 115, 60]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [[1, 115, 256], [[8, 1, 128], [8,\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m   \u001b[0m│                   │                  │        │       │\u001b[37m               \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                          1, 128]]]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ linear            │ ModuleList       │ 49.4 K │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ classifier        │ Linear           │    258 │ train │\u001b[37m \u001b[0m\u001b[37m[1, 115, 128]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ activation        │ Sigmoid          │      0 │ train │\u001b[37m \u001b[0m\u001b[37m  [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ validation_metric │ MetricCollection │      0 │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 27                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 27                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` \n",
       "has `__len__` defined. In combination with multi-process data loading (when num_workers &gt; 1), `__len__` could be \n",
       "inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` \n",
       "has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be \n",
       "inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training \n",
       "batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training \n",
       "batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vicuser/bp-stemmen-onderscheiden/pyannote/DiarizationErrorRate/epoch=9-v2.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getrainde model terug in aan de pipeline toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import pipelines\n",
    "finetuned_pipeline = pipelines.SpeakerDiarization(\n",
    "    segmentation=trained_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: instantiate after finetuning [github notebook](https://github.com/pyannote/pyannote-audio/blob/main/tutorials/adapting_pretrained_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f38e18572b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pipeline.instantiate(\n",
    "    pretrained_pipeline.parameters(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test result of trained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiarizationErrorRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:304\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:189\u001b[0m, in \u001b[0;36mSpeakerDiarization.default_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mtest():\n\u001b[0;32m----> 2\u001b[0m     file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinetuned_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     metric(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotation\u001b[39m\u001b[38;5;124m\"\u001b[39m], file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m], uem\u001b[38;5;241m=\u001b[39mfile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotated\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiarization error rate is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mabs\u001b[39m(metric)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% for the pretrained model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:306\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parameters()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate(default_parameters)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied."
     ]
    }
   ],
   "source": [
    "for file in protocol.test():\n",
    "    file[\"finetuned pipeline\"] = finetuned_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"finetuned pipeline\"], uem=file[\"annotated\"])\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")\n",
    "\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
