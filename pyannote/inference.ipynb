{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import pyannote\n",
    "\n",
    "# database related imports\n",
    "from pyannote.database import registry, FileFinder\n",
    "\n",
    "# training related imports\n",
    "from pyannote.audio import Pipeline, Model\n",
    "from pyannote.audio import pipelines\n",
    "from pyannote.audio.tasks import SpeakerDiarization\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "\n",
    "# metrics related imports\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "\n",
    "# other\n",
    "import os\n",
    "\n",
    "huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyannote\\database\\registry.py:499: UserWarning: Replacing existing BP.SpeakerDiarization.VlaamseAudio protocol by the one defined in 'C:\\Users\\verho\\Documents\\School\\2024-2025\\Bacherlorproef\\bp-stemmen-onderscheiden\\pyannote\\database.yml'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "registry.load_database(\"database.yml\")\n",
    "\n",
    "protocol = registry.get_protocol(\"BP.SpeakerDiarization.VlaamseAudio\", {\"audio\":FileFinder()})\n",
    "\n",
    "for file in protocol.train():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n",
    "\n",
    "for file in protocol.test():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n",
    "\n",
    "for file in protocol.development():\n",
    "   assert \"annotation\" in file\n",
    "   assert isinstance(file[\"annotation\"], pyannote.core.Annotation)\n",
    "   assert \"annotated\" in file\n",
    "   assert isinstance(file[\"annotated\"], pyannote.core.Timeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpeakerDiarization']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = registry.get_database(\"BP\")\n",
    "\n",
    "database.get_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained pyannote pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "# get the model from the pipeline\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=huggingface_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current error rate of the pipeline (possibly very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x0000017A51D1DA90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x0000017A51D1D280>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x0000017A52553DA0>\n",
      "<pyannote.database.protocol.protocol.ProtocolFile object at 0x0000017A524442F0>\n",
      "Diarization error rate is 10.3% for the pretrained model\n"
     ]
    }
   ],
   "source": [
    "metric = DiarizationErrorRate()\n",
    "\n",
    "for file in protocol.test():\n",
    "    print(file)\n",
    "    file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"])\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x17a5271c320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"pretrained pipeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x17a52724920>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"annotation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/660b9e20307a2b0cdb400d0f80aadc04a701fc54/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization at 0x7f6e1f332a70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyannote.audio\n",
    "import pyannote.audio.tasks\n",
    "\n",
    "\n",
    "pretrained_segm_model = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=huggingface_token)\n",
    "output_dir = \"./models\"\n",
    "\n",
    "task = pyannote.audio.tasks.Segmentation(\n",
    "    protocol,\n",
    "    batch_size=32,\n",
    "    vad_loss=\"bce\"\n",
    ")\n",
    "\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/vicuser/.local/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/vicuser/.local/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -   6.33% of all chunks contain no speech at all.\n",
      "   -  82.41% contain 1 speaker or less\n",
      "   -  98.73% contain 2 speakers or less\n",
      "   - 100.00% contain 3 speakers or less\n",
      "Setting `max_speakers_per_chunk` to 2. You can override this value (or avoid this estimation step) by passing `max_speakers_per_chunk=2` to the task constructor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicuser/.local/lib/python3.10/site-packages/pyannote/audio/core/model.py:229: UserWarning: Model has been trained for a different task. For fine tuning or transfer learning, it is recommended to train task-dependent layers for a few epochs before training the whole model: ['activation', 'classifier'].\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_segm_model.task = task\n",
    "# pretrained_segm_model.task.prepare_data()\n",
    "pretrained_segm_model.prepare_data()\n",
    "pretrained_segm_model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_segm_model.configure_optimizers = MethodType(configure_optimizers, pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                           Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ sincnet           │ SincNet          │ 42.6 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 32000] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                        [1, 60, 115] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ lstm              │ LSTM             │  1.4 M │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 115, 60] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [[1, 115, 256], [[8, 1, 128], [8, </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>│                   │                  │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                           1, 128]]] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ linear            │ ModuleList       │ 49.4 K │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ classifier        │ Linear           │    258 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 115, 128] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ activation        │ Sigmoid          │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 115, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         [1, 115, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ validation_metric │ MetricCollection │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                   ? </span>│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m                          Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ sincnet           │ SincNet          │ 42.6 K │ train │\u001b[37m \u001b[0m\u001b[37m[1, 1, 32000]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                       [1, 60, 115]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ lstm              │ LSTM             │  1.4 M │ train │\u001b[37m \u001b[0m\u001b[37m [1, 115, 60]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [[1, 115, 256], [[8, 1, 128], [8,\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m   \u001b[0m│                   │                  │        │       │\u001b[37m               \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                          1, 128]]]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ linear            │ ModuleList       │ 49.4 K │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ classifier        │ Linear           │    258 │ train │\u001b[37m \u001b[0m\u001b[37m[1, 115, 128]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ activation        │ Sigmoid          │      0 │ train │\u001b[37m \u001b[0m\u001b[37m  [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                        [1, 115, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ validation_metric │ MetricCollection │      0 │ train │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                  ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────┴───────────────┴─────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 27                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 27                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "An invalid dataloader was returned from `PyanNet.val_dataloader()`. Found None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:386\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# A prefix in the message to disambiguate between the train- and (optional) val dataloader that .fit() accepts\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_segm_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1054\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1054\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1083\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1083\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:120\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;129m@_no_grad_context\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[_OUT_DICT]:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:189\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dl \u001b[38;5;129;01min\u001b[39;00m combined_loader\u001b[38;5;241m.\u001b[39mflattened:\n\u001b[0;32m--> 189\u001b[0m     \u001b[43m_check_dataloader_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     dl \u001b[38;5;241m=\u001b[39m _process_dataloader(trainer, trainer_fn, stage, dl)\n\u001b[1;32m    191\u001b[0m     dataloaders\u001b[38;5;241m.\u001b[39mappend(dl)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:402\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_overridden(source\u001b[38;5;241m.\u001b[39mname, source\u001b[38;5;241m.\u001b[39minstance):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn invalid dataloader was passed to `Trainer.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_fn\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdataloaders=...)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataloader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Either pass the dataloader to the `.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_fn\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()` method OR implement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(self):` in your LightningModule/LightningDataModule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m     )\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn invalid dataloader was returned from `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(source\u001b[38;5;241m.\u001b[39minstance)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataloader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: An invalid dataloader was returned from `PyanNet.val_dataloader()`. Found None."
     ]
    }
   ],
   "source": [
    "trainer.fit(pretrained_segm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vicuser/bp-stemmen-onderscheiden/pyannote/DiarizationErrorRate/epoch=9-v2.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getrainde model terug in aan de pipeline toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import pipelines\n",
    "finetuned_pipeline = pipelines.SpeakerDiarization(\n",
    "    segmentation=trained_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: instantiate after finetuning [github notebook](https://github.com/pyannote/pyannote-audio/blob/main/tutorials/adapting_pretrained_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f38e18572b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pipeline.instantiate(\n",
    "    pretrained_pipeline.parameters(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test result of trained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiarizationErrorRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:304\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_diarization.py:189\u001b[0m, in \u001b[0;36mSpeakerDiarization.default_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mtest():\n\u001b[0;32m----> 2\u001b[0m     file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinetuned_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     metric(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotation\u001b[39m\u001b[38;5;124m\"\u001b[39m], file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m], uem\u001b[38;5;241m=\u001b[39mfile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotated\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiarization error rate is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mabs\u001b[39m(metric)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% for the pretrained model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:306\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m     default_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parameters()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate(default_parameters)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied."
     ]
    }
   ],
   "source": [
    "for file in protocol.test():\n",
    "    file[\"finetuned pipeline\"] = finetuned_pipeline(file)\n",
    "    metric(file[\"annotation\"], file[\"finetuned pipeline\"], uem=file[\"annotated\"])\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")\n",
    "\n",
    "\n",
    "print(f\"Diarization error rate is {100 * abs(metric):.1f}% for the pretrained model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
