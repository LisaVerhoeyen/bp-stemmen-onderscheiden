{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\verho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "huggingface_token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"../training_database/wavs/file1.wav\")\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "# start=0.2s stop=1.5s speaker_0\n",
    "# start=1.8s stop=3.9s speaker_1\n",
    "# start=4.2s stop=5.7s speaker_0\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "print(len(diarization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = []\n",
    "for segment in diarization.itersegments():\n",
    "    print(type(segment))\n",
    "    track = diarization.get_tracks(segment)\n",
    "    tracks.append(track)\n",
    "    print(type(next(iter(track))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_wav(\"../training_database/wavs/file1.wav\")\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    segment = audio[turn.start * 1000:turn.end * 1000]  # Convert seconds to milliseconds\n",
    "    segment.export(f\"./output/pyannote/speaker_{speaker}_{turn.start:.1f}-{turn.end:.1f}.wav\", format=\"wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
